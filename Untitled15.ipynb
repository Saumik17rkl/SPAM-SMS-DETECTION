{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7Ao2SKIPKM5+iG4+RggEI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"obsb-4wdJZh3","executionInfo":{"status":"ok","timestamp":1727017306769,"user_tz":-330,"elapsed":5611,"user":{"displayName":"Saumik Chakraborty","userId":"06470819357514319009"}}},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"]},{"cell_type":"code","source":["import pandas as pd\n","import zipfile\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Step 1: Unzip the dataset\n","zip_file_path = '/content/archive (9).zip'\n","extract_folder = 'sms_data'\n","\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_folder)\n"],"metadata":{"id":"zrUcYxI9JaPz","executionInfo":{"status":"ok","timestamp":1727017543058,"user_tz":-330,"elapsed":844,"user":{"displayName":"Saumik Chakraborty","userId":"06470819357514319009"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# prompt: read /content/sms_data\n","\n","df = pd.read_csv('/content/sms_data/spam.csv', encoding='latin-1')\n"],"metadata":{"id":"TvJqGlrZRDmo","executionInfo":{"status":"ok","timestamp":1727017664423,"user_tz":-330,"elapsed":627,"user":{"displayName":"Saumik Chakraborty","userId":"06470819357514319009"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","# Check the first few rows of the dataframe\n","print(df.head())\n","\n","# Step 2: Clean the Data\n","# Drop unnecessary columns if they exist\n","if 'Unnamed: 2' in df.columns:\n","    df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n","\n","# Rename columns for clarity\n","df.columns = ['label', 'message']\n","\n","# Map labels to binary values\n","df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n","\n","# Step 3: Split the data into training and testing sets\n","X = df['message']\n","y = df['label']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 4: Initialize TF-IDF Vectorizer\n","vectorizer = TfidfVectorizer()\n","X_train_tfidf = vectorizer.fit_transform(X_train)\n","X_test_tfidf = vectorizer.transform(X_test)\n","\n","# Step 5: Initialize and train the Logistic Regression model\n","model = LogisticRegression()\n","model.fit(X_train_tfidf, y_train)\n","\n","# Step 6: Make predictions\n","y_pred = model.predict(X_test_tfidf)\n","\n","# Step 7: Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aqnQsMnRHnn","executionInfo":{"status":"ok","timestamp":1727017759791,"user_tz":-330,"elapsed":1212,"user":{"displayName":"Saumik Chakraborty","userId":"06470819357514319009"}},"outputId":"88dd49a5-a1fa-4221-8d80-88810decd3b2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["     v1                                                 v2 Unnamed: 2  \\\n","0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n","1   ham                      Ok lar... Joking wif u oni...        NaN   \n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n","3   ham  U dun say so early hor... U c already then say...        NaN   \n","4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n","\n","  Unnamed: 3 Unnamed: 4  \n","0        NaN        NaN  \n","1        NaN        NaN  \n","2        NaN        NaN  \n","3        NaN        NaN  \n","4        NaN        NaN  \n","Accuracy: 0.9659192825112107\n","Confusion Matrix:\n"," [[964   1]\n"," [ 37 113]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98       965\n","           1       0.99      0.75      0.86       150\n","\n","    accuracy                           0.97      1115\n","   macro avg       0.98      0.88      0.92      1115\n","weighted avg       0.97      0.97      0.96      1115\n","\n"]}]},{"cell_type":"code","source":["#Import the MultinomialNB classifier\n","from sklearn.naive_bayes import MultinomialNB\n","# Import the SVC class\n","from sklearn.svm import SVC\n","\n","# Define a function to train and evaluate models\n","def train_and_evaluate(model, model_name):\n","    model.fit(X_train_tfidf, y_train)\n","    y_pred = model.predict(X_test_tfidf)\n","\n","    print(f\"{model_name} Results:\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","    print(\"-\" * 50)\n","\n","# Train and evaluate Naive Bayes\n","nb_model = MultinomialNB()\n","train_and_evaluate(nb_model, \"Naive Bayes\")\n","\n","# Train and evaluate Logistic Regression\n","lr_model = LogisticRegression()\n","train_and_evaluate(lr_model, \"Logistic Regression\")\n","\n","# Train and evaluate Support Vector Machine\n","svm_model = SVC() # Call the SVC class after importing it\n","train_and_evaluate(svm_model, \"Support Vector Machine\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pieTBeuyR6vl","executionInfo":{"status":"ok","timestamp":1727017891881,"user_tz":-330,"elapsed":7358,"user":{"displayName":"Saumik Chakraborty","userId":"06470819357514319009"}},"outputId":"ed306aa2-3274-4436-830a-b429a794d140"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes Results:\n","Accuracy: 0.9623318385650225\n","Confusion Matrix:\n"," [[965   0]\n"," [ 42 108]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98       965\n","           1       1.00      0.72      0.84       150\n","\n","    accuracy                           0.96      1115\n","   macro avg       0.98      0.86      0.91      1115\n","weighted avg       0.96      0.96      0.96      1115\n","\n","--------------------------------------------------\n","Logistic Regression Results:\n","Accuracy: 0.9659192825112107\n","Confusion Matrix:\n"," [[964   1]\n"," [ 37 113]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98       965\n","           1       0.99      0.75      0.86       150\n","\n","    accuracy                           0.97      1115\n","   macro avg       0.98      0.88      0.92      1115\n","weighted avg       0.97      0.97      0.96      1115\n","\n","--------------------------------------------------\n","Support Vector Machine Results:\n","Accuracy: 0.9820627802690582\n","Confusion Matrix:\n"," [[965   0]\n"," [ 20 130]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99       965\n","           1       1.00      0.87      0.93       150\n","\n","    accuracy                           0.98      1115\n","   macro avg       0.99      0.93      0.96      1115\n","weighted avg       0.98      0.98      0.98      1115\n","\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Load the dataset\n","data_file_path = '/content/sms_data/spam.csv'\n","df = pd.read_csv(data_file_path, encoding='latin-1')\n","\n","# Clean the Data\n","if 'Unnamed: 2' in df.columns:\n","    df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n","df.columns = ['label', 'message']\n","df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n","\n","# Split the data into training and testing sets\n","X = df['message']\n","y = df['label']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize TF-IDF Vectorizer\n","vectorizer = TfidfVectorizer()\n","X_train_tfidf = vectorizer.fit_transform(X_train)\n","X_test_tfidf = vectorizer.transform(X_test)\n","\n","# Define a function to train and evaluate models\n","def train_and_evaluate(model, model_name):\n","    model.fit(X_train_tfidf, y_train)\n","    y_pred = model.predict(X_test_tfidf)\n","\n","    print(f\"{model_name} Results:\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","    print(\"-\" * 50)\n","\n","# Train and evaluate Naive Bayes\n","nb_model = MultinomialNB()\n","train_and_evaluate(nb_model, \"Naive Bayes\")\n","\n","# Train and evaluate Logistic Regression\n","lr_model = LogisticRegression()\n","train_and_evaluate(lr_model, \"Logistic Regression\")\n","\n","# Train and evaluate Support Vector Machine\n","svm_model = SVC()\n","train_and_evaluate(svm_model, \"Support Vector Machine\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1E7L-R4KSHqZ","executionInfo":{"status":"ok","timestamp":1727017908813,"user_tz":-330,"elapsed":4657,"user":{"displayName":"Saumik Chakraborty","userId":"06470819357514319009"}},"outputId":"f243cb08-1857-4deb-827e-5221a9034754"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes Results:\n","Accuracy: 0.9623318385650225\n","Confusion Matrix:\n"," [[965   0]\n"," [ 42 108]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98       965\n","           1       1.00      0.72      0.84       150\n","\n","    accuracy                           0.96      1115\n","   macro avg       0.98      0.86      0.91      1115\n","weighted avg       0.96      0.96      0.96      1115\n","\n","--------------------------------------------------\n","Logistic Regression Results:\n","Accuracy: 0.9659192825112107\n","Confusion Matrix:\n"," [[964   1]\n"," [ 37 113]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98       965\n","           1       0.99      0.75      0.86       150\n","\n","    accuracy                           0.97      1115\n","   macro avg       0.98      0.88      0.92      1115\n","weighted avg       0.97      0.97      0.96      1115\n","\n","--------------------------------------------------\n","Support Vector Machine Results:\n","Accuracy: 0.9820627802690582\n","Confusion Matrix:\n"," [[965   0]\n"," [ 20 130]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99       965\n","           1       1.00      0.87      0.93       150\n","\n","    accuracy                           0.98      1115\n","   macro avg       0.99      0.93      0.96      1115\n","weighted avg       0.98      0.98      0.98      1115\n","\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Step 1: Load the dataset\n","data_file_path = '/content/sms_data/spam.csv'  # Adjust this path if necessary\n","df = pd.read_csv(data_file_path, encoding='latin-1')\n","\n","# Step 2: Clean the Data\n","# Drop unnecessary columns if they exist\n","if 'Unnamed: 2' in df.columns:\n","    df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n","\n","# Rename columns for clarity\n","df.columns = ['label', 'message']\n","\n","# Map labels to binary values (0 for ham, 1 for spam)\n","df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n","\n","# Step 3: Split the data into training and testing sets\n","X = df['message']\n","y = df['label']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 4: Initialize TF-IDF Vectorizer\n","vectorizer = TfidfVectorizer()\n","X_train_tfidf = vectorizer.fit_transform(X_train)\n","X_test_tfidf = vectorizer.transform(X_test)\n","\n","# Step 5: Define a function to train and evaluate models\n","def train_and_evaluate(model, model_name):\n","    model.fit(X_train_tfidf, y_train)\n","    y_pred = model.predict(X_test_tfidf)\n","\n","    print(f\"{model_name} Results:\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","    print(\"-\" * 50)\n","\n","# Step 6: Train and evaluate Naive Bayes\n","nb_model = MultinomialNB()\n","train_and_evaluate(nb_model, \"Naive Bayes\")\n","\n","# Step 7: Train and evaluate Logistic Regression\n","lr_model = LogisticRegression(max_iter=1000)  # Increase max_iter for convergence\n","train_and_evaluate(lr_model, \"Logistic Regression\")\n","\n","# Step 8: Train and evaluate Support Vector Machine\n","svm_model = SVC()\n","train_and_evaluate(svm_model, \"Support Vector Machine\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JjpzFANbSeSm","executionInfo":{"status":"ok","timestamp":1727017987605,"user_tz":-330,"elapsed":5886,"user":{"displayName":"Saumik Chakraborty","userId":"06470819357514319009"}},"outputId":"6c0e4ba4-13d0-4abb-b22b-461f687b57d0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes Results:\n","Accuracy: 0.9623318385650225\n","Confusion Matrix:\n"," [[965   0]\n"," [ 42 108]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98       965\n","           1       1.00      0.72      0.84       150\n","\n","    accuracy                           0.96      1115\n","   macro avg       0.98      0.86      0.91      1115\n","weighted avg       0.96      0.96      0.96      1115\n","\n","--------------------------------------------------\n","Logistic Regression Results:\n","Accuracy: 0.9659192825112107\n","Confusion Matrix:\n"," [[964   1]\n"," [ 37 113]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98       965\n","           1       0.99      0.75      0.86       150\n","\n","    accuracy                           0.97      1115\n","   macro avg       0.98      0.88      0.92      1115\n","weighted avg       0.97      0.97      0.96      1115\n","\n","--------------------------------------------------\n","Support Vector Machine Results:\n","Accuracy: 0.9820627802690582\n","Confusion Matrix:\n"," [[965   0]\n"," [ 20 130]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99       965\n","           1       1.00      0.87      0.93       150\n","\n","    accuracy                           0.98      1115\n","   macro avg       0.99      0.93      0.96      1115\n","weighted avg       0.98      0.98      0.98      1115\n","\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":["import joblib\n","\n","# Save the model and vectorizer\n","joblib.dump(nb_model, 'spam_detection_model.pkl')\n","joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tiAptsHsSxLv","executionInfo":{"status":"ok","timestamp":1727018016910,"user_tz":-330,"elapsed":613,"user":{"displayName":"Saumik Chakraborty","userId":"06470819357514319009"}},"outputId":"8773a4c3-a522-4ea3-fef9-f997f5884496"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['tfidf_vectorizer.pkl']"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":[],"metadata":{"id":"plH3nd5RS5n4"},"execution_count":null,"outputs":[]}]}